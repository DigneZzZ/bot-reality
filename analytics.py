import asyncio
import json
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional
import redis.asyncio as redis
from collections import defaultdict, Counter
import logging

class AnalyticsCollector:
    """–°–æ–±–∏—Ä–∞–µ—Ç –∏ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –±–æ—Ç–∞"""
    
    def __init__(self, redis_client: redis.Redis):
        self.redis = redis_client
    
    async def log_domain_check(
        self,
        user_id: int,
        domain: str,
        check_type: str,  # "short" –∏–ª–∏ "full"
        result_status: str,  # "success", "failed", "cached"
        execution_time: Optional[float] = None
    ) -> None:
        """–õ–æ–≥–∏—Ä—É–µ—Ç –ø—Ä–æ–≤–µ—Ä–∫—É –¥–æ–º–µ–Ω–∞"""
        timestamp = datetime.now().isoformat()
        
        # –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        await self.redis.incr("analytics:total_checks")
        await self.redis.incr(f"analytics:daily:{datetime.now().strftime('%Y%m%d')}")
        await self.redis.incr(f"analytics:user:{user_id}:total")
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ç–∏–ø–∞–º –ø—Ä–æ–≤–µ—Ä–æ–∫
        await self.redis.incr(f"analytics:check_type:{check_type}")
        await self.redis.incr(f"analytics:result_status:{result_status}")
        
        # –î–µ—Ç–∞–ª—å–Ω—ã–π –ª–æ–≥ (—Ö—Ä–∞–Ω–∏–º 30 –¥–Ω–µ–π)
        log_entry = {
            "timestamp": timestamp,
            "user_id": user_id,
            "domain": domain,
            "check_type": check_type,
            "result_status": result_status,
            "execution_time": execution_time
        }
        
        await self.redis.lpush(
            "analytics:detailed_logs",
            json.dumps(log_entry)
        )
        await self.redis.expire("analytics:detailed_logs", 86400 * 30)  # 30 –¥–Ω–µ–π
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –¥–æ–º–µ–Ω–∞–º
        await self.redis.zincrby("analytics:popular_domains", 1, domain)
        
        # –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
        if execution_time:
            await self.redis.lpush(f"analytics:performance:{check_type}", execution_time)
            await self.redis.ltrim(f"analytics:performance:{check_type}", 0, 999)  # –ü–æ—Å–ª–µ–¥–Ω–∏–µ 1000
    
    async def log_user_activity(self, user_id: int, action: str, details: Optional[str] = None) -> None:
        """–õ–æ–≥–∏—Ä—É–µ—Ç –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
        timestamp = datetime.now().isoformat()
        
        # –ê–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        await self.redis.incr(f"analytics:user:{user_id}:actions")
        await self.redis.incr(f"analytics:action:{action}")
        
        # –ü–æ—Å–ª–µ–¥–Ω—è—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å
        activity_data = {
            "timestamp": timestamp,
            "action": action,
            "details": details
        }
        await self.redis.set(
            f"analytics:user:{user_id}:last_activity",
            json.dumps(activity_data),
            ex=86400 * 7  # –•—Ä–∞–Ω–∏–º 7 –¥–Ω–µ–π
        )
    
    async def get_analytics_summary(self, days: int = 7) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–∞–µ—Ç —Å–≤–æ–¥–∫—É –∞–Ω–∞–ª–∏—Ç–∏–∫–∏ –∑–∞ —É–∫–∞–∑–∞–Ω–Ω—ã–π –ø–µ—Ä–∏–æ–¥"""
        end_date = datetime.now()
        start_date = end_date - timedelta(days=days)
        
        # –ë–∞–∑–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        total_checks = await self.redis.get("analytics:total_checks") or 0
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –¥–Ω—è–º
        daily_stats = {}
        for i in range(days):
            date = (end_date - timedelta(days=i)).strftime('%Y%m%d')
            count = await self.redis.get(f"analytics:daily:{date}") or 0
            daily_stats[date] = int(count)
        
        # –ü–æ–ø—É–ª—è—Ä–Ω—ã–µ –¥–æ–º–µ–Ω—ã
        popular_domains = await self.redis.zrevrange("analytics:popular_domains", 0, 9, withscores=True)
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ç–∏–ø–∞–º –ø—Ä–æ–≤–µ—Ä–æ–∫
        short_checks = await self.redis.get("analytics:check_type:short") or 0
        full_checks = await self.redis.get("analytics:check_type:full") or 0
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º
        success_count = await self.redis.get("analytics:result_status:success") or 0
        failed_count = await self.redis.get("analytics:result_status:failed") or 0
        cached_count = await self.redis.get("analytics:result_status:cached") or 0
        
        # –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
        performance_stats = await self._get_performance_stats()
        
        return {
            "period": {"start": start_date.isoformat(), "end": end_date.isoformat()},
            "total_checks": int(total_checks),
            "daily_stats": daily_stats,
            "popular_domains": [(domain.decode() if isinstance(domain, bytes) else domain, int(score)) 
                              for domain, score in popular_domains],
            "check_types": {
                "short": int(short_checks),
                "full": int(full_checks)
            },
            "results": {
                "success": int(success_count),
                "failed": int(failed_count),
                "cached": int(cached_count)
            },
            "performance": performance_stats
        }
    
    async def _get_performance_stats(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
        stats = {}
        
        for check_type in ["short", "full"]:
            times = await self.redis.lrange(f"analytics:performance:{check_type}", 0, -1)
            if times:
                times = [float(t) for t in times]
                stats[check_type] = {
                    "avg_time": sum(times) / len(times),
                    "min_time": min(times),
                    "max_time": max(times),
                    "total_samples": len(times)
                }
            else:
                stats[check_type] = {
                    "avg_time": 0,
                    "min_time": 0,
                    "max_time": 0,
                    "total_samples": 0
                }
        
        return stats
    
    async def get_user_stats(self, user_id: int) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
        total_checks = await self.redis.get(f"analytics:user:{user_id}:total") or 0
        total_actions = await self.redis.get(f"analytics:user:{user_id}:actions") or 0
        
        # –ü–æ—Å–ª–µ–¥–Ω—è—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å
        last_activity_data = await self.redis.get(f"analytics:user:{user_id}:last_activity")
        last_activity = None
        if last_activity_data:
            try:
                last_activity = json.loads(last_activity_data)
            except json.JSONDecodeError:
                pass
        
        return {
            "user_id": user_id,
            "total_checks": int(total_checks),
            "total_actions": int(total_actions),
            "last_activity": last_activity
        }
    
    async def generate_analytics_report(self, admin_id: int) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç—á–µ—Ç –¥–ª—è –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–∞"""
        summary = await self.get_analytics_summary(days=7)
        
        report = "üìä <b>–ê–Ω–∞–ª–∏—Ç–∏–∫–∞ –±–æ—Ç–∞ (7 –¥–Ω–µ–π)</b>\n\n"
        
        # –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        report += f"üî¢ <b>–û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:</b>\n"
        report += f"‚Ä¢ –í—Å–µ–≥–æ –ø—Ä–æ–≤–µ—Ä–æ–∫: {summary['total_checks']}\n"
        report += f"‚Ä¢ –£—Å–ø–µ—à–Ω—ã—Ö: {summary['results']['success']}\n"
        report += f"‚Ä¢ –ù–µ—É–¥–∞—á–Ω—ã—Ö: {summary['results']['failed']}\n"
        report += f"‚Ä¢ –ò–∑ –∫—ç—à–∞: {summary['results']['cached']}\n\n"
        
        # –¢–∏–ø—ã –ø—Ä–æ–≤–µ—Ä–æ–∫
        total_type_checks = summary['check_types']['short'] + summary['check_types']['full']
        if total_type_checks > 0:
            short_pct = (summary['check_types']['short'] / total_type_checks) * 100
            full_pct = (summary['check_types']['full'] / total_type_checks) * 100
            report += f"üìã <b>–¢–∏–ø—ã –ø—Ä–æ–≤–µ—Ä–æ–∫:</b>\n"
            report += f"‚Ä¢ –ö—Ä–∞—Ç–∫–∏–µ: {summary['check_types']['short']} ({short_pct:.1f}%)\n"
            report += f"‚Ä¢ –ü–æ–ª–Ω—ã–µ: {summary['check_types']['full']} ({full_pct:.1f}%)\n\n"
        
        # –ü–æ–ø—É–ª—è—Ä–Ω—ã–µ –¥–æ–º–µ–Ω—ã
        if summary['popular_domains']:
            report += f"üåê <b>–¢–æ–ø-5 –¥–æ–º–µ–Ω–æ–≤:</b>\n"
            for i, (domain, count) in enumerate(summary['popular_domains'][:5], 1):
                report += f"{i}. {domain} ({count} —Ä–∞–∑)\n"
            report += "\n"
        
        # –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
        perf = summary['performance']
        if perf['short']['total_samples'] > 0:
            report += f"‚ö° <b>–ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å:</b>\n"
            report += f"‚Ä¢ –ö—Ä–∞—Ç–∫–∏–µ: {perf['short']['avg_time']:.1f}—Å (—Å—Ä–µ–¥–Ω–µ–µ)\n"
            report += f"‚Ä¢ –ü–æ–ª–Ω—ã–µ: {perf['full']['avg_time']:.1f}—Å (—Å—Ä–µ–¥–Ω–µ–µ)\n\n"
        
        # –ê–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –ø–æ –¥–Ω—è–º
        report += f"üìÖ <b>–ê–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –ø–æ –¥–Ω—è–º:</b>\n"
        for date, count in sorted(summary['daily_stats'].items(), reverse=True)[:7]:
            date_formatted = datetime.strptime(date, '%Y%m%d').strftime('%d.%m')
            report += f"‚Ä¢ {date_formatted}: {count} –ø—Ä–æ–≤–µ—Ä–æ–∫\n"
        
        return report

    async def cleanup_old_data(self, days_to_keep: int = 30) -> None:
        """–û—á–∏—â–∞–µ—Ç —Å—Ç–∞—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ –∞–Ω–∞–ª–∏—Ç–∏–∫–∏"""
        cutoff_date = datetime.now() - timedelta(days=days_to_keep)
        
        # –û—á–∏—â–∞–µ–º –¥–Ω–µ–≤–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        for i in range(days_to_keep, days_to_keep + 30):  # –ü—Ä–æ–≤–µ—Ä—è–µ–º –µ—â–µ 30 –¥–Ω–µ–π –Ω–∞–∑–∞–¥
            old_date = (datetime.now() - timedelta(days=i)).strftime('%Y%m%d')
            await self.redis.delete(f"analytics:daily:{old_date}")
        
        logging.info(f"Cleaned up analytics data older than {days_to_keep} days")
